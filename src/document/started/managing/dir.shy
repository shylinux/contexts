title "目录结构"
spark `Contexts 运行时常用的目录与文件如下。`
chain `
contexts
	src
		main.go
		main.js
		main.shy
		version.go
		binpack.go
		template/
		document/
	etc
		init.shy
		local.shy
		exit.shy
	bin
		ice.bin
	var
		conf
		data
		file
		log
		tmp
		proxy
	usr
		publish
		install
		local
			export
			daemon
			image
			repos
			work
		node_modules
`

chapter "源码目录 src/"
spark `所有的代码与文档，都保存这个目录里。`

section "main.go"
spark `main.go 是主程序的入口文件，在 Contexts 的项目中，所有功能都是模块化的，通过 init 函数隐式注册，所以只需要在 main.go 文件中添加一行 import 即可引入模块。
所以 main.go 只剩下一行代码<code>ice.Run()</code>。`
spark inner src/main.go

section "main.js"
spark `main.js 是前端的入口文件，前端的代码也是全部模块化，并且是后端驱动。所以 main.js 只需要定义导航栏的功能列表即可。现在只支持两级目录。支持图标，可自行引入图标库。`
spark inner src/main.js

section "main.shy"
spark `main.shy 是文档入口，文档工具默认打开的文件。Contexts 对笔记文档提供了非常多的支持，因为笔记文档是用户使用最频率也是最方便的工具。`
spark inner src/main.shy

section "version.go"
spark `version.go 是项目源码及编译相关的信息。`
spark inner src/version.go

section "binpack.go"
spark `binpack.go 是打包文件，在编译构建时，Contexts 会把 js、css、shy 等文件，直接打包进执行程序中。
进程运行时，直接在内存里构建了一个文件系统。`

section "template/"
spark `template/ 是模板目录，比如生成网页、生成笔记时，会用到很多格式化的文本，用户可以随时修改这些模板文件，满足定制化的需要。`

section "document/"
spark `document/ 是文档目录，官网展示的页面与文档，都保存在这里，可以随时修改。`
spark `其中 src/document/index.shy 定义标题栏。src/document/xxx/index.shy 定义导航栏，其它文件都是普通的文档文件。`

chapter "配置目录 etc/"
spark `Contexts 在运行中用到的配置文件都保存在这个目录。`

section "init.shy"
spark `init.shy 是 Contexts 的启动脚本。一些定制化的配置可以直接添加到这个文件中。如权限管理、事件触发、桌面定制、编译配置等`

section "local.shy"
spark `etc/ 目录中的其它配置文件，都会打包进程序文件中向外发布。只有 local.shy 会被忽略，所以如果配置中有密码之类的敏感信息，可以保存在这个文件中。`

section "exit.shy"
spark `exit.shy 是 Contexts 在服务停止前，执行的脚本，如一些运行数据的需要保存。`

chapter "程序目录 bin/"
spark `bin/ice.bin 就是 Contexts 的程序文件，ice 是 icebergs 的缩写，因为后端框架叫冰山架，寓意是后端功能非常丰富庞大，但平时只能看到冰山一角。`

chapter "数据目录 var/"
section "conf/"
spark `Contexts 实现了一种内存版的数据库，每个工具，都会自动创建配置管理与数据存储，数据的读写、保存、维护全部托管给框架，不需要开发者专门去注意。`
spark `在服务进程退出时，会将内存版的数据库中的所有数据，都会保存到这个目录。在服务重新启动时，会再加载到内存。`

section "data/"
spark `Contexts 数据库的数据默认是在内存中，但数据量超过一定大小时，将一部分不常用的数据保存磁盘中的 ./var/data/ 目录里，当这些数据被访问时，会直接读写磁盘。`

section "file/"
spark `有些文件类的数据，大小超过512B，会直接保存到这个目录里，在内存里只保存一个文件名。`

section "log/"
spark `log/ 日志文件的目录`
order `
bench.log 运行日志
error.log 错误日志
debug.log 调试日志
watch.log 监控日志
boot.log 启动日志
ice.pid 进程ID
`

section "tmp/"
spark `tmp/ 临时目录`

section "proxy/"
spark `proxy/ 代理目录，当通过网页访问子空间或是子设备时，会用到一些文件，它们都会被缓存到这个目录里。`

chapter "资源目录 usr/"
section "publish/"
spark `发布资源，这个目录下的所有文件，都是对外公开的文件，如发布的程序文件和配置文件，用户可以自由的下载。`

section "install/"
spark `安装一些软件与工具的目录。`

section "local/"
spark `local 就是私有的一些数据，在数据读写时会有更多的权限检查，以保证用户的数据安全。`

section "local/export/"
spark `local/export/ 就是配置和数据导出的目录，因为运行时的数据量比较大，当有一些重要的数据需要备份或是和代码一起提交，可导出到这个目录。`

section "local/daemon/"
spark `启动的后台进程，以端口号作为目录名。`

section "local/image/"
spark `图片视频等多媒体文件。`

section "local/repos/"
spark `Contexts 自带了 Git-Server 的功能，可以直接提供代码仓库的服务，所有的仓库代码都保存到这个目录。`

section "local/work/"
spark `子空间的目录，Contexts 创建的所有空间都在这个目录。`

section "node_modules/"
spark `Contexts 的前端代码，用到的外部依赖库，会自动下载到这个目录。`
